{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18898123",
   "metadata": {},
   "source": [
    "# Lab 4: Momentum II\n",
    "\n",
    "In the last lab we explored how to backtest decile portfolio style trading strategies. In this lab we will explore how to backtest portfolios that are optimized each period to maximize alpha while minimizing variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1f288",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sf_quant.data as sfd\n",
    "import sf_quant.optimizer as sfo\n",
    "import sf_quant.backtester as sfb\n",
    "import sf_quant.performance as sfp\n",
    "import polars as pl\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4f703",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We import the necessary data for you here. We will be doing a backtest from 2023-01-01 to 2024-01-31. However since our signal takes 1 year to compute, we will really only be backtesting 1 month of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a4213",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = dt.date(2023, 1, 1)\n",
    "end = dt.date(2024, 1, 31)\n",
    "\n",
    "columns = [\n",
    "    'date',\n",
    "    'barrid',\n",
    "    'ticker',\n",
    "    'price',\n",
    "    'return',\n",
    "    'specific_risk',\n",
    "    'predicted_beta'\n",
    "]\n",
    "\n",
    "data = sfd.load_assets(\n",
    "    start=start,\n",
    "    end=end,\n",
    "    in_universe=True,\n",
    "    columns=columns\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6583f",
   "metadata": {},
   "source": [
    "## Compute the Momentum Signal\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Compute momentum for each security and date as the rolling 230 day return (you can just use log returns here).\n",
    "- Shift the momentum signal 22 days. This will results in the 11 month return from t-12 to t-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e368fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_compute_momentum(data: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the t_12 to t_2 momentum signal for each secrutiy and date combination.\n",
    "    \n",
    "    Args:\n",
    "        data (pl.DataFrame): Data frame containing date, barrid, price, and return columns.\n",
    "    \n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame with columns date, barrid, price, return, and momentum columns.\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass\n",
    "\n",
    "momentum = task_compute_momentum(data)\n",
    "\n",
    "momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103df9e3",
   "metadata": {},
   "source": [
    "## Compute the Alphas\n",
    "\n",
    "In order to make our momentum signal usable in our optimizer we will use a predetermined Information Coefficient of 0.05 and the forecasted idiosyncratic risk provided by Barra to convert our signal into alpha forecasts.\n",
    "\n",
    "### Instructions\n",
    "- For each date z-score the momentum signal across all asssets cross sectionally and call this `score`.\n",
    "- Using the `specific_risk` column compute the alphas as `0.05` * `score` * `specific_risk`.\n",
    "- Note: Make sure to divide `specific_risk` by 100 to put it in decimal space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_compute_alphas(momentum: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\" \n",
    "    Compute the alphas for each security and date combo.\n",
    "\n",
    "    Args:\n",
    "        momentum (pl.DataFrame): Data frame containing barrid, date, specific_risk, and momentum columns.\n",
    "    \n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing barrid, date, specific_risk, momentum, score, and alpha columns.\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass\n",
    "\n",
    "alphas = task_compute_alphas(momentum)\n",
    "\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_price_filter(alphas: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter the universe to lagged price greater than 5 and non-null alpha.\n",
    "    \n",
    "    Args:\n",
    "        alphas (pl.DataFrame): Data frame containing barrid, date, specific_risk, momentum, score, and alpha columns.\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing barrid, date, specific_risk, momentum, score, and alpha columns.\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass\n",
    "\n",
    "price_filter = task_price_filter(alphas)\n",
    "\n",
    "price_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b134e",
   "metadata": {},
   "source": [
    "## Backtest\n",
    "\n",
    "Now that we have our alphas we will compute the MVO portfolios for each date in our sample.\n",
    "\n",
    "### Instructions\n",
    "- Use the `FullInvestment`, `LongOnly`, `NoBuyingOnMargin`, and `UnitBeta` constraints.\n",
    "- For each unique date in the `price_filter` data frame find the optimal weights using `sf_quant.optimizer.mve_optimizer`.\n",
    "- Note: for the `UnitBeta` constraint to work you will need to provide the predicted betas to the optimizer in each itteration.\n",
    "- Hint: the optimizer assumes that your alpha vector and covariance matrix are both sorted the same way.\n",
    "- Hint: use a gamma of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46de1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_backtest(price_filter: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the optimal portfolio weights for each day in our sample.\n",
    "    \n",
    "    Args:\n",
    "        price_filter (pl.DataFrame): Data frame containing barrid, date, specific_risk, momentum, score, and alpha columns.\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing barrid, date, and weight columns.\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass\n",
    "\n",
    "weights = task_backtest(price_filter)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf5739e",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Now that we have our optimal weights we will join the returns from our initial dataset. \n",
    "\n",
    "### Instructions\n",
    "- Join the returns from `data` and compute the return and cumulative return of the portfolio using the optimal weights.\n",
    "- Note: since our covariance matrix isn't lagged we will need to shift our returns forward. To do this use `.shift(-1)` by `barrid` and call it `fwd_return`.\n",
    "- Chart the cumulative returns of the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6035ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_compute_returns(weights: pl.DataFrame, data: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\" \n",
    "    Compute the optimal portfolio returns.\n",
    "\n",
    "    Args:\n",
    "        weights (pl.DataFrame): Data frame containing barrid, date, and weight columns.\n",
    "        data (pl.DataFrame): Data frame containing barrid, date, and return columns\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing date, fwd_return, and cumulative_fwd_return_columns\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass           \n",
    "\n",
    "returns = task_compute_returns(weights, data)\n",
    "\n",
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Chart the cumulative returns of the portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c6c46",
   "metadata": {},
   "source": [
    "## Benchmark Decomposition\n",
    "\n",
    "You should find that our portfolio is up and to the right. But the question is how much of that is due to the market being up versus our signal being good. We will find out by joining the benchmark weights to our `weights` data frame and computing the active weights.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Pull in the benchmark weights using `sf_quant.data.load_benchmark`.\n",
    "- Join the benchmark weights to the optimal weights.\n",
    "- Compute the active weights as `weight` - `weight_bmk` = `weight_act`\n",
    "- Unpivot the weight columns and compute the forward return for each portfolio (total, benchmark, and active). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef508f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_return_decomposition(weights: pl.DataFrame, data: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\" \n",
    "    Compute the forward returns for the total, benchmark, and active portfolios.\n",
    "\n",
    "    Args:\n",
    "        weights (pl.DataFrame): Data frame containing barrid, date, and weight columns.\n",
    "        data (pl.DataFrame): Data frame containing barrid, date, and return columns\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing date, portfolio, fwd_return, and cumulative_fwd_return columns        \n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass\n",
    "\n",
    "returns_decomp = task_return_decomposition(weights, data)\n",
    "\n",
    "returns_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Chart the cumulative returns of each portfolio\n",
    "# HINT: Use seaborn.lineplot() with the attribute hue='portfolio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d271c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the annual average return, annual volatility, and annualized sharpe ratio for each portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b4b5a",
   "metadata": {},
   "source": [
    "## `sf_quant` Backtester Module\n",
    "\n",
    "That was a lot of fun right? Just kidding. All of that code takes a lot of work. That's why we've implemented a backtester in the `sf_quant` package. Let's practice using it really quick and compare our results.\n",
    "\n",
    "### Instructions\n",
    "- Declare your constraints the same way you did previously.\n",
    "- Use a gamma of 10.\n",
    "- Find the optimal weights using the `sf_quant.backtester` module.\n",
    "- Hint: use the `backtest_parallel()` module to run your backtest in parallel across all the cores on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d4fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_backtest_sf(price_filter: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\" \n",
    "    Compute the optimal portfolio weights using the `sf_quant` package.\n",
    "\n",
    "    Args:\n",
    "        price_filter (pl.DataFrame): Data frame containing barrid, date, specific_risk, momentum, score, and alpha columns.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing barrid, date, and weight columns.\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass\n",
    "\n",
    "weights_sf = task_backtest_sf(price_filter)\n",
    "\n",
    "weights_sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa70bd84",
   "metadata": {},
   "source": [
    "## `sf_quant` Performance Package\n",
    "\n",
    "It's also not a lot of fun to merge the returns dataset and do a full decomposition manually. You can do that with `sf_quant.performance` too.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Compute the portfolio forward returns decomposition using the `generate_returns_from_weights` function.\n",
    "- Chart the cumulative returns of the portfolios using the `generate_returns_chart` function.\n",
    "- Generate the summary table using the `generate_summary_table` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_return_decomposition_sf(weights_sf: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\" \n",
    "    Compute the returns decomposition using the `sf_quant` package.\n",
    "\n",
    "    Args:\n",
    "        weights_sf (pl.DataFrame): Data frame containing date, barrid, and weight columns.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Data frame containing date, portfolio, and return (fwd_return) columns\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function.\n",
    "    pass\n",
    "\n",
    "returns_sf = task_return_decomposition_sf(weights_sf)\n",
    "\n",
    "returns_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate the returns chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate the summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0ae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sf-quant-labs (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
